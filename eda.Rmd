---
title: "EDA"
author: "Kylie Wheelock Riley"
date: "10/3/2019"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(viridis)

knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  fig.width = 8, 
  fig.height = 6,
  out.width = "90%")

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))

```

## Exploratory data analysis using group_by
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(c("USW00094728", "USC00519397", "USS0023B17S"),
                      var = c("PRCP", "TMIN", "TMAX"), 
                      date_min = "2017-01-01",
                      date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY", 
                      USC00519397 = "Waikiki_HA",
                      USS0023B17S = "Waterhole_WA"),
    tmin = tmin / 10,
    tmax = tmax / 10,
    month = lubridate::floor_date(date, unit = "month")) %>%
  ##created month using lubridate
  select(name, id, date, month, everything())
```

## 'group_by' for categorcial variables
```{r}
weather_df %>% 
  group_by(name, month)
##R will keep the groupings, so you may need to ungroup ()
```

## Counting
```{r}
weather_df %>%
  count(month, name = "n_days")
```

```{r}

##If you just want a count of things you can go straight to count, no need to group and summarize
weather_df %>% 
  count(name)

weather_df %>% 
  count(month)

weather_df %>% 
  count(name, month)

## can also use name in count, the default is n
```

##Creating a table using r markdown format
```{r}
weather_df %>%
  pull(month) %>% 
  table 

##making a nice table to export
weather_df %>% 
  count(name) %>%
  knitr::kable()
```

## Summarize
```{r}
##Summarize the number of observations in each month and the number of distinct values of date in each month.
weather_df %>%
  group_by(month) %>%
  summarize(
    n_obs = n(),
    n_days = n_distinct(date))

```

## 2x2 tables 
```{r}
weather_df %>% 
  mutate(
    cold = case_when(
      tmax < 5 ~ "cold",
      tmax >=5 ~ "not_cold",
      TRUE     ~ ""
  )) %>% 
  filter(name != "Waikiki_HA") %>% 
  group_by(name, cold) %>% 
  summarize(count = n())


##^^ Tidy data table, but want to get it in formatting for 2x2
weather_df %>% 
  mutate(cold = case_when(
    tmax < 5 ~ "cold",
    tmax >=5 ~ "not_cold",
    TRUE     ~ ""
  )) %>% 
  filter(name != "Waikiki_HA") %>% 
  janitor::tabyl(name, cold)

```


## general summaries
```{r}
weather_df %>%
  group_by(month) %>%
  summarize(
    mean_tmax = mean(tmax),
    mean_prec = mean(prcp, na.rm = TRUE),
    median_tmax = median(tmax),
    sd_tmax = sd(tmax))
## There are NAs in the dataset, r will return NA/NAN because you cant take the mean of nothing, need to remove the NAs (na.rm = TRUE)

## group by more than1 summary
weather_df %>%
  group_by(name, month) %>%
  summarize(
    mean_tmax = mean(tmax),
    median_tmax = median(tmax))
```

```{r}
##using summarize to make a plot
weather_df %>%
  group_by(name, month) %>%
  summarize(mean_tmax = mean(tmax)) %>%
  ggplot(aes(x = month, y = mean_tmax, color = name)) + 
    geom_point() + geom_line() + 
    theme(legend.position = "bottom")
```


## pivot to make more reader friendly summaries
```{r}
weather_df %>% 
  group_by(name) %>% 
  summarize(mean_tmax = mean(tmax)) %>% 
pivot_wider(
  names_from = name, 
  values_from = mean_tmax) %>% 
  knitr::kable(digits = 1)
  
```

 
## group with mutate
```{r}
weather_df %>%
  group_by(name) %>%
  mutate(centered_tmax = tmax - mean(tmax)) %>% 
  ggplot(aes(x = date, y = centered_tmax, color = name)) + 
    geom_point()

```

## window functions in grouped mutate
window function take n inputs and return n outputs, and the outputs depend on all the inputs. There are several categories of window functions; you’re most likely to need ranking functions and offsets, which we illustrate below.
```{r}
weather_df %>% 
  group_by(name, month) %>% 
  mutate(
    tmax_rank = min_rank(tmax)
  ) %>% 
  filter(tmax_rank == 1)

##only keeping day with lowest max temp
weather_df %>%
  group_by(name, month) %>%
  filter(min_rank(tmax) < 2)
```

## Lags!
Offsets, especially lags, are used to compare an observation to it’s previous value. This is useful, for example, to find the day-by-day change in max temperature within each station over the year:
```{r}
weather_df %>%
  group_by(name) %>%
  mutate(temp_change = tmax - lag(tmax))

##This kind of variable might be used to quantify the day-by-day variability in max temperature, or to identify the largest one-day increase:
weather_df %>%
  group_by(name) %>%
  mutate(temp_change = tmax - lag(tmax)) %>%
  summarize(temp_change_sd = sd(temp_change, na.rm = TRUE),
            temp_change_max = max(temp_change, na.rm = TRUE))
```

# Learning Assessment 1
In the PULSE data, the primary outcome is BDI score; it’s observed over follow-up visits, and we might ask if the typical BDI score values are roughly similar at each. Try to write a code chunk that imports, cleans, and summarizes the PULSE data to examine the mean and median at each visit. Export the results of this in a reader-friendly format.
```{r}
library(haven)
pulse_data = read_sas("./data/public_pulse_data.sas7bdat") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    bdi_score_bl:bdi_score_12m,
    names_to = "visit", 
    names_prefix = "bdi_score_",
    values_to = "bdi") %>%
  select(id, visit, everything()) %>%
  mutate(visit = recode(visit, "bl" = "00m"),
         visit = factor(visit, levels = str_c(c("00", "01", "06", "12"), "m")))

pulse_data %>% 
  group_by(visit) %>% 
  summarize(
    mean_bdi = mean(bdi, na.rm = TRUE),
    median_bdi = median(bdi, na.rm = TRUE)) %>% 
  knitr::kable(digits = 3)
  
```

# Learning Assessment 2